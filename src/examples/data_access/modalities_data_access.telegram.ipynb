{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FrostAura Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping frostaura as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "USE_LOCAL_CODE: bool = True # NOTE: When changing this configuration, be sure to restart the interpreter in order to have sys path updates reflect.\n",
    "directories_to_move_up: int = 2\n",
    "current_executing_path: str = os.getcwd()\n",
    "current_executing_path = current_executing_path.replace('\\\\', '/')\n",
    "root_path: str = '/'.join(current_executing_path.split('/')[:-directories_to_move_up])\n",
    "\n",
    "# Clean up.\n",
    "%pip uninstall frostaura -y\n",
    "sys.path = [p for p in sys.path if p != root_path]\n",
    "\n",
    "if USE_LOCAL_CODE:\n",
    "    sys.path.append(root_path)\n",
    "else:\n",
    "    %pip install -U --no-cache-dir frostaura"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deanmartin/miniforge3/envs/tensorflow-apple-metal/lib/python3.9/site-packages/whisper/timing.py:58: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def backtrace(trace: np.ndarray):\n"
     ]
    }
   ],
   "source": [
    "from frostaura.data_access import IModalitiesDataAccess\n",
    "from frostaura.data_access import TelegramModalitiesDataAccess"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ffmpeg\n",
    "#%pip install -U transformers torchaudio sentencepiece pydub openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /ydshieh/vit-gpt2-coco-en/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /ydshieh/vit-gpt2-coco-en/resolve/main/generation_config.json HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /ydshieh/vit-gpt2-coco-en/resolve/main/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /ydshieh/vit-gpt2-coco-en/resolve/main/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "/Users/deanmartin/miniforge3/envs/tensorflow-apple-metal/lib/python3.9/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "modalities_data_access: IModalitiesDataAccess = TelegramModalitiesDataAccess()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deanmartin/miniforge3/envs/tensorflow-apple-metal/lib/python3.9/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript:  Sure does. And there it is. Project Escalon is a surveillance program operated by the US.\n"
     ]
    }
   ],
   "source": [
    "audio_file_path: str = '/Users/deanmartin/Source/fa.intelligence.notebooks/src/data/voicenote_583bc72a-45a8-4321-be6e-3fa6da40d9f5.mp3'\n",
    "text: str = modalities_data_access.sound_file_to_text(audio_file_path)\n",
    "\n",
    "print(f'Transcript: {text}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deanmartin/miniforge3/envs/tensorflow-apple-metal/lib/python3.9/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: [{'generated_text': 'a computer screen with a picture of a person on it '}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "image_file_path: str = '/Users/deanmartin/Source/fa.intelligence.notebooks/src/data/photo_fde08ef2-2d99-4ef1-9830-f7a9fc89aee6.png'\n",
    "text: str = modalities_data_access.image_file_to_text(image_file_path)\n",
    "\n",
    "print(f'Transcript: {text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): fki.tic.heia-fr.ch:443\n",
      "DEBUG:urllib3.connectionpool:https://fki.tic.heia-fr.ch:443 \"GET /static/img/a01-122-02-00.jpg HTTP/1.1\" 200 4472\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/trocr-base-handwritten/resolve/main/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/trocr-base-handwritten/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/trocr-base-handwritten/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /microsoft/trocr-base-handwritten/resolve/main/generation_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'indus the'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# load image from the IAM database\n",
    "url = 'https://fki.tic.heia-fr.ch/static/img/a01-122-02-00.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')\n",
    "model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')\n",
    "pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "generated_ids = model.generate(pixel_values)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "windows-ml-station",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2d2799229849fd2c86aa3751486a343a6caa647b525ae379976f27c22f61e0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
